{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict, namedtuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from utils import SparseFeat, DenseFeat#, build_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarLenSparseFeat(namedtuple('VarLenFeat',\n",
    "                                  ['name', 'dimension', 'maxlen', 'combiner', 'use_hash', 'dtype', 'embedding_name',\n",
    "                                   'embedding'])):\n",
    "    __slots__ = ()\n",
    "\n",
    "    def __new__(cls, name, dimension, maxlen, combiner=\"mean\", use_hash=False, dtype=\"float32\", embedding_name=None,\n",
    "                embedding=True):\n",
    "        if embedding_name is None:\n",
    "            embedding_name = name\n",
    "        return super(VarLenSparseFeat, cls).__new__(cls, name, dimension, maxlen, combiner, use_hash, dtype,\n",
    "                                                    embedding_name, embedding)\n",
    "    \n",
    "def split(x):\n",
    "    key_ans = x.split('|')\n",
    "    for key in key_ans:\n",
    "        if key not in key2index:\n",
    "            # Notice : input value 0 is a special \"padding\",so we do not use 0 to encode valid feature for sequence input\n",
    "            key2index[key] = len(key2index) + 1\n",
    "    return list(map(lambda x: key2index[x], key_ans))\n",
    "\n",
    "\n",
    "def build_input_features(feature_columns):\n",
    "    features = OrderedDict()\n",
    "\n",
    "    start = 0\n",
    "    for feat in feature_columns:\n",
    "        feat_name = feat.name\n",
    "        if feat_name in features:\n",
    "            continue\n",
    "        if isinstance(feat, SparseFeat):\n",
    "            features[feat_name] = (start, start + 1)\n",
    "            start += 1\n",
    "        elif isinstance(feat, DenseFeat):\n",
    "            features[feat_name] = (start, start + feat.dimension)\n",
    "            start += feat.dimension\n",
    "        elif isinstance(feat,VarLenSparseFeat):\n",
    "            features[feat_name] = (start, start + feat.maxlen)\n",
    "            start += feat.maxlen\n",
    "        else:\n",
    "            raise TypeError(\"Invalid feature column type,got\",type(feat))\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_feature_names(feature_columns):\n",
    "    features = build_input_features(feature_columns)\n",
    "    return list(features.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data/private/Ad/ml-20m/'\n",
    "file_name = 'movielens_sample.txt'\n",
    "\n",
    "data = pd.read_csv(root+file_name)\n",
    "sparse_features = [\"movie_id\", \"user_id\",\n",
    "                   \"gender\", \"age\", \"occupation\", \"zip\", ]\n",
    "target = ['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "# preprocess the sequence feature\n",
    "\n",
    "key2index= {}\n",
    "genres_list = list(map(split, data['genres'].values))\n",
    "genres_length = np.array(list(map(len, genres_list)))\n",
    "max_len = max(genres_length)\n",
    "# Notice : padding=`post`\n",
    "genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.count #unique features for each sparse field and generate feature config for sequence feature\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
    "                    for feat in sparse_features]\n",
    "varlen_feature_columns = [VarLenSparseFeat('genres', len(\n",
    "    key2index) + 1, max_len, 'mean')]  # Notice : value 0 is for padding for sequence input feature\n",
    "\n",
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.generate input data for model\n",
    "model_input = {name:data[name] for name in target+feature_names if name!='genres'}\n",
    "model_input = np.concatenate((np.stack(list(model_input.values()), -1), genres_list), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(model_input, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(root+'np_prepro/dataset_fm.pkl', 'wb') as f:\n",
    "    pickle.dump(train, f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(test, f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(feature_names, f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump((linear_feature_columns, dnn_feature_columns), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 12),\n",
       " (200, 10),\n",
       " 5,\n",
       " ['movie_id', 'user_id', 'gender', 'age', 'occupation', 'zip', 'genres'])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, data.shape, max_len, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-20M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data/private/Ad/ml-20m/'\n",
    "\n",
    "ratings = pd.read_csv(root+'ratings.csv')\n",
    "movies = pd.read_csv(root+'movies.csv')\n",
    "\n",
    "sparse_features = [\"userId\", \"movieId\"]#, \"genres\"]\n",
    "target = ['rating']\n",
    "\n",
    "data = pd.merge(ratings, movies)\n",
    "data.loc[:,'rating'] = data['rating'].map(lambda x: 1 if x > 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "# preprocess the sequence feature\n",
    "\n",
    "key2index= {}\n",
    "genres_list = list(map(split, data['genres'].values))\n",
    "genres_length = np.array(list(map(len, genres_list)))\n",
    "max_len = max(genres_length)\n",
    "# Notice : padding=`post`\n",
    "genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.count #unique features for each sparse field and generate feature config for sequence feature\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
    "                    for feat in sparse_features]\n",
    "varlen_feature_columns = [VarLenSparseFeat('genres', len(\n",
    "    key2index) + 1, max_len, 'mean')]  # Notice : value 0 is for padding for sequence input feature\n",
    "\n",
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.generate input data for model\n",
    "model_input = {name:data[name] for name in target+feature_names if name!='genres'}\n",
    "model_input = np.concatenate((np.stack(list(model_input.values()), -1), genres_list), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(model_input, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(root+'np_prepro/dataset_fm.pkl', 'wb') as f:\n",
    "    pickle.dump(train, f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(test, f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump(feature_names, f, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle.dump((linear_feature_columns, dnn_feature_columns), f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
